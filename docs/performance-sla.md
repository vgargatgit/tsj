# TSJ Performance SLA Draft (TSJ-18)

This draft defines initial performance targets for the TSJ MVP execution path.
Targets are based on benchmark telemetry generated by `tsj bench` and tracked as CI artifacts.

## Benchmark Source of Truth

- Command:
  - `tsj bench benchmarks/tsj-benchmark-baseline.json --warmup 1 --iterations 2`
- Artifact:
  - `benchmark-baseline-report` (uploaded by CI)
- Report file schema:
  - `benchmarks/tsj-benchmark-baseline.json`

## Initial Targets

| Metric | Scope | Target (Initial) | Tracking Method |
| --- | --- | --- | --- |
| Startup latency | `micro-startup-hello` run average | <= 250 ms | `results[].runAvgMs` |
| Compile+startup latency | full suite average compile+run | <= 1200 ms | `summary.avgCompileMs + summary.avgRunMs` |
| Throughput | full suite avg ops/sec | >= 20,000 ops/sec | `summary.avgThroughputOpsPerSec` |
| Peak memory delta | max across suite | <= 96 MiB | `summary.maxPeakMemoryBytes` |

## Notes and Assumptions

1. This SLA is CI-environment-relative, not a universal hardware guarantee.
2. Benchmark values are directional and should be trended over time.
3. Regressions should be investigated when any target is exceeded by more than 15% on two consecutive CI runs.
4. The `--smoke` benchmark profile is for local fast feedback and is not the SLA baseline.
